{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46bd914d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import *\n",
    "from utils import *\n",
    "from generate_csbm import *\n",
    "from models import *\n",
    "from train import *\n",
    "from setup import *\n",
    "from torch.optim import SGD\n",
    "\n",
    "import torch \n",
    "import copy\n",
    "import pickle\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from os.path import exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e52cbbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "csbm = cSBM(N=200, p=100, d=8, mu=0.5, l=2)\n",
    "csbm.generate_node_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9008259",
   "metadata": {},
   "outputs": [],
   "source": [
    "csbm.generate_node_data(method=\"SNC\", n_local=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9acfc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_tilde = calculate_Atilde(csbm.A, K=10, alpha=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "155365cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "initial_model = MLP(csbm.Xs[0].shape[1], 64, 2, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "390a870f",
   "metadata": {},
   "outputs": [],
   "source": [
    "server = set_up_GC(csbm.Xs, csbm.ys, initial_model, A_tilde, n_train=30, n_val=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2f5f03d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Communication: 1 Average train loss: 0.68882 Average train accuracy: 0.530 Average val loss: 0.68870 Average val accuracy: 0.530\n",
      "Communication: 2 Average train loss: 0.68857 Average train accuracy: 0.530 Average val loss: 0.68849 Average val accuracy: 0.530\n",
      "Communication: 3 Average train loss: 0.68834 Average train accuracy: 0.530 Average val loss: 0.68829 Average val accuracy: 0.530\n",
      "Communication: 4 Average train loss: 0.68810 Average train accuracy: 0.530 Average val loss: 0.68808 Average val accuracy: 0.530\n",
      "Communication: 5 Average train loss: 0.68785 Average train accuracy: 0.530 Average val loss: 0.68787 Average val accuracy: 0.530\n",
      "Communication: 6 Average train loss: 0.68760 Average train accuracy: 0.530 Average val loss: 0.68765 Average val accuracy: 0.530\n",
      "Communication: 7 Average train loss: 0.68734 Average train accuracy: 0.530 Average val loss: 0.68743 Average val accuracy: 0.530\n",
      "Communication: 8 Average train loss: 0.68707 Average train accuracy: 0.530 Average val loss: 0.68719 Average val accuracy: 0.531\n",
      "Communication: 9 Average train loss: 0.68679 Average train accuracy: 0.530 Average val loss: 0.68696 Average val accuracy: 0.531\n",
      "Communication: 10 Average train loss: 0.68651 Average train accuracy: 0.530 Average val loss: 0.68671 Average val accuracy: 0.531\n",
      "Communication: 11 Average train loss: 0.68621 Average train accuracy: 0.531 Average val loss: 0.68646 Average val accuracy: 0.531\n",
      "Communication: 12 Average train loss: 0.68591 Average train accuracy: 0.531 Average val loss: 0.68620 Average val accuracy: 0.531\n",
      "Communication: 13 Average train loss: 0.68560 Average train accuracy: 0.531 Average val loss: 0.68593 Average val accuracy: 0.531\n",
      "Communication: 14 Average train loss: 0.68528 Average train accuracy: 0.531 Average val loss: 0.68565 Average val accuracy: 0.531\n",
      "Communication: 15 Average train loss: 0.68495 Average train accuracy: 0.532 Average val loss: 0.68537 Average val accuracy: 0.531\n",
      "Communication: 16 Average train loss: 0.68461 Average train accuracy: 0.532 Average val loss: 0.68507 Average val accuracy: 0.531\n",
      "Communication: 17 Average train loss: 0.68426 Average train accuracy: 0.532 Average val loss: 0.68477 Average val accuracy: 0.531\n",
      "Communication: 18 Average train loss: 0.68389 Average train accuracy: 0.533 Average val loss: 0.68446 Average val accuracy: 0.531\n",
      "Communication: 19 Average train loss: 0.68352 Average train accuracy: 0.533 Average val loss: 0.68414 Average val accuracy: 0.532\n",
      "Communication: 20 Average train loss: 0.68313 Average train accuracy: 0.534 Average val loss: 0.68380 Average val accuracy: 0.532\n",
      "Communication: 21 Average train loss: 0.68273 Average train accuracy: 0.535 Average val loss: 0.68346 Average val accuracy: 0.533\n",
      "Communication: 22 Average train loss: 0.68232 Average train accuracy: 0.536 Average val loss: 0.68310 Average val accuracy: 0.535\n",
      "Communication: 23 Average train loss: 0.68189 Average train accuracy: 0.537 Average val loss: 0.68273 Average val accuracy: 0.535\n",
      "Communication: 24 Average train loss: 0.68145 Average train accuracy: 0.538 Average val loss: 0.68235 Average val accuracy: 0.536\n",
      "Communication: 25 Average train loss: 0.68099 Average train accuracy: 0.538 Average val loss: 0.68196 Average val accuracy: 0.537\n",
      "Communication: 26 Average train loss: 0.68052 Average train accuracy: 0.541 Average val loss: 0.68156 Average val accuracy: 0.540\n",
      "Communication: 27 Average train loss: 0.68003 Average train accuracy: 0.542 Average val loss: 0.68114 Average val accuracy: 0.539\n",
      "Communication: 28 Average train loss: 0.67952 Average train accuracy: 0.543 Average val loss: 0.68070 Average val accuracy: 0.539\n",
      "Communication: 29 Average train loss: 0.67899 Average train accuracy: 0.545 Average val loss: 0.68025 Average val accuracy: 0.542\n",
      "Communication: 30 Average train loss: 0.67845 Average train accuracy: 0.547 Average val loss: 0.67979 Average val accuracy: 0.544\n",
      "Communication: 31 Average train loss: 0.67790 Average train accuracy: 0.549 Average val loss: 0.67932 Average val accuracy: 0.546\n",
      "Communication: 32 Average train loss: 0.67732 Average train accuracy: 0.553 Average val loss: 0.67883 Average val accuracy: 0.550\n",
      "Communication: 33 Average train loss: 0.67672 Average train accuracy: 0.555 Average val loss: 0.67832 Average val accuracy: 0.552\n",
      "Communication: 34 Average train loss: 0.67611 Average train accuracy: 0.559 Average val loss: 0.67780 Average val accuracy: 0.559\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/qb/qvxrwz454mj92jl_h79qv2t80000gn/T/ipykernel_92257/4187733406.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     train_loss, train_acc, val_loss, val_acc = server.communication(batch_size=15, learning_rate=0.05, \n\u001b[1;32m      6\u001b[0m                                                                     \u001b[0mI\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                                                                     gradient=True, noise=False)\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/GFL-APPNP/GFLAPPNP_GC.py\u001b[0m in \u001b[0;36mcommunication\u001b[0;34m(self, batch_size, learning_rate, I, gradient, noise)\u001b[0m\n\u001b[1;32m    247\u001b[0m                                            \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m                                            \u001b[0mI\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m                                            gradient)\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_aggregation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/GFL-APPNP/GFLAPPNP_GC.py\u001b[0m in \u001b[0;36mlocal_update\u001b[0;34m(self, A_tilde_k_d, A_tilde_k_gd, C_k, dH, batch_size, learning_rate, I, gradient)\u001b[0m\n\u001b[1;32m    119\u001b[0m                     \u001b[0mlocal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m                     \u001b[0mlocal_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m                     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m                         \u001b[0my_onehot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m                         \u001b[0my_onehot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/MachineLearning/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_internal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_scripting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_communication = 100\n",
    "pre_n_communication = 0\n",
    "for ith in range(num_communication):\n",
    "        \n",
    "    train_loss, train_acc, val_loss, val_acc = server.communication(batch_size=15, learning_rate=0.05, \n",
    "                                                                    I=10, \n",
    "                                                                    gradient=True, noise=False)\n",
    "\n",
    "\n",
    "    print (f\"Communication:\", ith+1+pre_n_communication, \n",
    "            \"Average train loss:\", \"{:.5f}\".format(train_loss), \"Average train accuracy:\", \"{:.3f}\".format(train_acc),\n",
    "            \"Average val loss:\", \"{:.5f}\".format(val_loss), \"Average val accuracy:\", \"{:.3f}\".format(val_acc), flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd1f25b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
